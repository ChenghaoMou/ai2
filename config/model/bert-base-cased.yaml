model: bert-base-cased
accumulate_grad_batches: 1
adam_epsilon: 1e-8
batch_size: 48
learning_rate: 2e-5
max_length: 128
precision: full # Half precision only works best with volta architectures such as V100
warmup_steps: 0
